{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a84747",
   "metadata": {},
   "source": [
    "**Generator Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de27d98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:46:26.060312Z",
     "start_time": "2021-05-13T16:46:26.035277Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_to_pass(para):   #Module to get the read text from the user and convert it into sentence for comparison\n",
    "    import re\n",
    "    import string\n",
    "    import nltk\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    para = \"\".join([i for i in para if i not in string.punctuation])\n",
    "    para = \"\".join([i.lower() for i in para if i not in string.punctuation])\n",
    "    para = para.replace('\\n',' ')\n",
    "    para = para.replace(\"%\",\" Percentage\")\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b422990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:46:27.596622Z",
     "start_time": "2021-05-13T16:46:27.586627Z"
    }
   },
   "outputs": [],
   "source": [
    "def gpt2_generator():\n",
    "    import torch\n",
    "    from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "    #initialize tokenizer and model from pretrained GPT2 model\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "\n",
    "    list_of_sequences = [\n",
    "    'Out of office during the 1930s, Churchill took the lead in calling for British rearmament to counter the growing threat of militarism in Nazi Germany. At the outbreak of the Second World War he was re-appointed First Lord of the Admiralty. In May 1940, he became Prime Minister, replacing Neville Chamberlain. Churchill oversaw British involvement in the Allied war effort against the Axis powers, resulting in victory in 1945. After the Conservatives defeat in the 1945 general election, he became Leader of the Opposition',\n",
    "    'Artificial intelligence was founded as an academic discipline in 1955, and in the years since has experienced several waves of optimism,followed by disappointment and the loss of funding (known as an \"AI winter\"), followed by new approaches, success and renewed funding. After AlphaGo successfully defeated a professional Go player in 2015, artificial intelligence once again attracted widespread global attention',\n",
    "    'Technology has many effects. It has helped develop more advanced economies (including todays global economy) and has allowed the rise of a leisure class. Many technological processes produce unwanted by-products known as pollution and deplete natural resources to the detriment of Earths environment. Innovations have always influenced the values of a society and raised new questions in the ethics of technology. Examples include the rise of the notion of efficiency in terms of human productivity, and the challenges of bioethics',\n",
    "    'Nature has furnished us with numerous significant assets like water, air, food, therapeutic plants, fire, fuels, woods, and trees, and so forth. Every one of these assets helps us for different purposes. As a whole, we realize that our endurance will turn out to be difficult or end without them. As they serve us, they likewise need our adoration and service.',\n",
    "    'We should love every creation of God, regardless of whether a plant or a creature. We should treat them with affection, and attempt to secure them, however much as it is possible to do. Likewise, cherishing nature incorporates keeping the air and water clean, planting numerous trees, taking care of the variety of animals, treating harmed creatures or helpless humans, and so on. Our acts of love will include a touch of paradise the earth',\n",
    "    'Everybody makes a few companions at various phases of life. A few companionships last more while some end in only a couple of months. The fundamental explanation for it is the presence of love. Indeed, even we ought to have a sentiment of affection for the needy and poor. They deserve our love the most. We should that is why show our love and affection to everybody irrespective of any differences among each other'\n",
    "                    ]\n",
    "    import random\n",
    "    sequence = list_of_sequences[random.randint(0, 5)]\n",
    "    \n",
    "    inputs = tokenizer.encode(sequence, return_tensors='pt')\n",
    "\n",
    "    # we pass a maximum output length of 200 tokens\n",
    "    outputs = model.generate(inputs, max_length=200, do_sample=True)\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    clean_text = clean_to_pass(text)\n",
    "\n",
    "    return {\n",
    "    'to_read':text,\n",
    "    'to_check':clean_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9931df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:47:21.789362Z",
     "start_time": "2021-05-13T16:46:28.609081Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "text_dict = gpt2_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f441295",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:47:21.805284Z",
     "start_time": "2021-05-13T16:47:21.793281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read The Below Sentence after the timer goes off,ignore the complex/unwanted Characters\n"
     ]
    }
   ],
   "source": [
    "print(\"Read The Below Sentence after the timer goes off,ignore the complex/unwanted Characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10cfde42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:47:21.837281Z",
     "start_time": "2021-05-13T16:47:21.814284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         \n"
     ]
    }
   ],
   "source": [
    "print(\"                         \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c8ce33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:47:21.853304Z",
     "start_time": "2021-05-13T16:47:21.839277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We should love every creation of God, regardless of whether a plant or a creature. We should treat them with affection, and attempt to secure them, however much as it is possible to do. Likewise, cherishing nature incorporates keeping the air and water clean, planting numerous trees, taking care of the variety of animals, treating harmed creatures or helpless humans, and so on. Our acts of love will include a touch of paradise the earth will recognize and love with no need to leave that which they find there. The way of life and of life in general have evolved. This includes the evolution of our species to find life on other worlds, while at the same time developing us to our fullest potential (like the sun does with sunlight). We do not accept such an evolution. We simply believe (as most of us are) that the way is perfect. If they have been left in the world by a man, and had not been left us by a beast, we don't want to be held\n"
     ]
    }
   ],
   "source": [
    "print(text_dict['to_read'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71377558",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1564625b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aca1c5",
   "metadata": {},
   "source": [
    "**Recording Phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643c781c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:47:31.952933Z",
     "start_time": "2021-05-13T16:47:21.855276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read it out!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def countdown(t):\n",
    "    \n",
    "    while t:\n",
    "        mins, secs = divmod(t, 60)\n",
    "        timer = '{:02d}:{:02d}'.format(mins, secs)\n",
    "        print(timer, end=\"\\r\")\n",
    "        time.sleep(1)\n",
    "        t -= 1\n",
    "      \n",
    "    print('Read it out!')\n",
    "\n",
    "countdown(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11a19c61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:48:42.638001Z",
     "start_time": "2021-05-13T16:48:42.625035Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_out():\n",
    "    import pyaudio\n",
    "    import wave\n",
    "\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    RECORD_SECONDS = 20\n",
    "    WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"* recording\")\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    \n",
    "    print(\"* done recording\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58c3631b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:49:03.647167Z",
     "start_time": "2021-05-13T16:48:43.169194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "read_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272227e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3492aada",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfdb75f",
   "metadata": {},
   "source": [
    "**Convertion Module** \n",
    "- Text  ( intelligence score  1/ 0 )\n",
    "- Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02a609",
   "metadata": {},
   "source": [
    "1.) Text - Issue with API Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78e592a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:49:13.799248Z",
     "start_time": "2021-05-13T16:49:13.792252Z"
    }
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "774dc8ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:49:14.396042Z",
     "start_time": "2021-05-13T16:49:14.377057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'adjust_for_ambient_noise',\n",
       " 'dynamic_energy_adjustment_damping',\n",
       " 'dynamic_energy_ratio',\n",
       " 'dynamic_energy_threshold',\n",
       " 'energy_threshold',\n",
       " 'listen',\n",
       " 'listen_in_background',\n",
       " 'non_speaking_duration',\n",
       " 'operation_timeout',\n",
       " 'pause_threshold',\n",
       " 'phrase_threshold',\n",
       " 'recognize_api',\n",
       " 'recognize_bing',\n",
       " 'recognize_google',\n",
       " 'recognize_google_cloud',\n",
       " 'recognize_houndify',\n",
       " 'recognize_ibm',\n",
       " 'recognize_sphinx',\n",
       " 'recognize_wit',\n",
       " 'record',\n",
       " 'snowboy_wait_for_hot_word']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6ace856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:49:21.509138Z",
     "start_time": "2021-05-13T16:49:16.169059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: patient love every creation of god regardless of whether a plant or a creature of patient with them with affection and attempt to secular however much as it is possible to do likewise cherish in nature in corporates keeping the air and water clean planting numerous trees are taking care of the variety of animals treating harmed creatures are\n"
     ]
    }
   ],
   "source": [
    "hellow=sr.WavFile('output.wav')\n",
    "with hellow as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "    try:\n",
    "        s = r.recognize_google(audio).lower()\n",
    "        print(\"Text: \"+s)\n",
    "        intelligence_score = 1\n",
    "    except Exception as e:\n",
    "        print(\"Exception: \"+str(e))\n",
    "        intelligence_score = 0\n",
    "        print(\"Final Try? Read Again, Ensure a Calm Environment / API Error\")\n",
    "        s = text_dict['to_read'][:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec8ea29a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:49:29.031458Z",
     "start_time": "2021-05-13T16:49:29.026452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patient love every creation of god regardless of whether a plant or a creature of patient with them with affection and attempt to secular however much as it is possible to do likewise cherish in nature in corporates keeping the air and water clean planting numerous trees are taking care of the variety of animals treating harmed creatures are'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219087e",
   "metadata": {},
   "source": [
    "2.) Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b7ed878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:49:35.109314Z",
     "start_time": "2021-05-13T16:49:32.328550Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "from memory_profiler import memory_usage\n",
    "from matplotlib import figure\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09559e0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:49:35.809456Z",
     "start_time": "2021-05-13T16:49:35.801443Z"
    }
   },
   "outputs": [],
   "source": [
    "#use the same function , by changing the directory for test set creating\n",
    "def create_spectrogram_images(filename,name):\n",
    "    count_ = 0\n",
    "    plt.interactive(False)\n",
    "    clip,sample_rate = librosa.load(filename,sr=None)\n",
    "    fig = plt.figure(figsize=[0.74,0.74])\n",
    "    \n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    \n",
    "    s = librosa.feature.melspectrogram(y=clip,sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(s,ref=np.max))\n",
    "    \n",
    "    filename =  name + '.jpg'\n",
    "    count_+=1\n",
    "    plt.savefig(filename,dpi=400,bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()\n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,s\n",
    "    \n",
    "def outside_fn():\n",
    "    \n",
    "    file = \"output.wav\"\n",
    "    filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "    name = str(\"output\")\n",
    "    create_spectrogram_images(filename,name)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42200b00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:49:37.846158Z",
     "start_time": "2021-05-13T16:49:37.528043Z"
    }
   },
   "outputs": [],
   "source": [
    "outside_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93d93a34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:50:00.127235Z",
     "start_time": "2021-05-13T16:50:00.111237Z"
    }
   },
   "outputs": [],
   "source": [
    "#Outputs\n",
    "#text: s \n",
    "#image: output.jpg\n",
    "#intelligence score: 1 - Intelligent Audio / 0- Unintelligent Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b885589",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:57:25.648023Z",
     "start_time": "2021-05-13T16:57:25.630020Z"
    }
   },
   "outputs": [],
   "source": [
    "#deleting the wav file\n",
    "import os\n",
    "os.remove(\"output.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeef24c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d73ec",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27cfa6f",
   "metadata": {},
   "source": [
    "**AI-Module Run**\n",
    "- Docu Similarity  ( s vs text_dict['to_check'] )\n",
    "- Image -> Spectrogram Analysis ( output.jpg  Analysis )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a65c986",
   "metadata": {},
   "source": [
    "1.) Document Similarity Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1925e868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:51:53.053766Z",
     "start_time": "2021-05-13T16:51:52.616854Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c82f060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:52:08.677035Z",
     "start_time": "2021-05-13T16:52:08.665038Z"
    }
   },
   "outputs": [],
   "source": [
    "class DocSim:\n",
    "    def __init__(self, w2v_model, stopwords=None):\n",
    "        self.w2v_model = w2v_model\n",
    "        self.stopwords = stopwords if stopwords is not None else []\n",
    "\n",
    "    def vectorize(self, doc: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Identify the vector values for each word in the given document\n",
    "        :param doc:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        doc = doc.lower()\n",
    "        words = [w for w in doc.split(\" \") if w not in self.stopwords]\n",
    "        word_vecs = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                vec = self.w2v_model[word]\n",
    "                word_vecs.append(vec)\n",
    "            except KeyError:\n",
    "                # Ignore, if the word doesn't exist in the vocabulary\n",
    "                pass\n",
    "\n",
    "        # Assuming that document vector is the mean of all the word vectors\n",
    "        # PS: There are other & better ways to do it.\n",
    "        vector = np.mean(word_vecs, axis=0)\n",
    "        return vector\n",
    "\n",
    "    def _cosine_sim(self, vecA, vecB):\n",
    "        \"\"\"Find the cosine similarity distance between two vectors.\"\"\"\n",
    "        csim = np.dot(vecA, vecB) / (np.linalg.norm(vecA) * np.linalg.norm(vecB))\n",
    "        if np.isnan(np.sum(csim)):\n",
    "            return 0\n",
    "        return csim\n",
    "\n",
    "    def calculate_similarity(self, source_doc, target_docs=None, threshold=0):\n",
    "        \"\"\"Calculates & returns similarity scores between given source document & all\n",
    "        the target documents.\"\"\"\n",
    "        if not target_docs:\n",
    "            return []\n",
    "\n",
    "        if isinstance(target_docs, str):\n",
    "            target_docs = [target_docs]\n",
    "\n",
    "        source_vec = self.vectorize(source_doc)\n",
    "        results = []\n",
    "        for doc in target_docs:\n",
    "            target_vec = self.vectorize(doc)\n",
    "            sim_score = self._cosine_sim(source_vec, target_vec)\n",
    "            if sim_score > threshold:\n",
    "                results.append({\"score\": sim_score, \"doc\": doc})\n",
    "            # Sort results by score in desc order\n",
    "            results.sort(key=lambda k: k[\"score\"], reverse=True)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc15af53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T16:52:28.424449Z",
     "start_time": "2021-05-13T16:52:28.400415Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_tfidf_similarity(source_doc,target_docs):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # To make uniformed vectors, both documents need to be combined first.\n",
    "    target_docs.insert(0, source_doc)\n",
    "    embeddings = vectorizer.fit_transform(target_docs)\n",
    "\n",
    "    cosine_similarities = cosine_similarity(embeddings[0:1], embeddings[1:]).flatten()\n",
    "\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for i, score in enumerate(cosine_similarities):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = i\n",
    "\n",
    "    return highest_score\n",
    " # The text that we get from the converted voice note.\n",
    "\n",
    "\n",
    "def predict(source_doc,target_docs,model_path):\n",
    "    \n",
    "    \n",
    "    w2v_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "    ds = DocSim(w2v_model)\n",
    "\n",
    "    sim_scores = ds.calculate_similarity(source_doc, target_docs)\n",
    "    tf_score = process_tfidf_similarity(source_doc,target_docs)\n",
    "\n",
    "    sim_score = 0\n",
    "\n",
    "    if((sim_scores[0]['score']>=0.4) and (tf_score>=0.4)):\n",
    "        document_similar = True\n",
    "        sim_score = (sim_scores[0]['score']+tf_score)/2\n",
    "    else:\n",
    "        document_similar = False\n",
    "        sim_score = (sim_scores[0]['score']+tf_score)/2\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    return ({\"Score \":sim_score,\n",
    "    \"document_similar\":document_similar})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6baf55ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:00:54.947604Z",
     "start_time": "2021-05-13T16:59:54.135332Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = r'Models\\GoogleNews-vectors-negative300.bin'\n",
    "prediction = predict(text_dict['to_check'],[s],model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0f0f3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:02:14.084147Z",
     "start_time": "2021-05-13T17:02:12.328155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Score ': 0.754874370835486, 'document_similar': True}\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ee226ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:19:01.498251Z",
     "start_time": "2021-05-13T17:19:01.484249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.754874370835486"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction['Score ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9aed1833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:25:49.463801Z",
     "start_time": "2021-05-13T18:25:49.455766Z"
    }
   },
   "outputs": [],
   "source": [
    "if(prediction['Score ']>=0.5):\n",
    "    if(prediction['Score ']>=0.95):\n",
    "        score_1 = prediction['Score ']-0.1\n",
    "    elif (prediction['Score ']>0.6 and prediction['Score ']<0.95):\n",
    "        score_1 = prediction['Score ']-0.1\n",
    "    else:\n",
    "        score_1 = prediction['Score ']\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39334d81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:25:49.821413Z",
     "start_time": "2021-05-13T18:25:49.801416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.654874370835486"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24882a",
   "metadata": {},
   "source": [
    "2.) Image Spectrogram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92012e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
